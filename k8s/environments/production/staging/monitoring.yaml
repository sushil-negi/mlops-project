apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
  namespace: healthcare-ai-production
data:
  prometheus.yml: |
    global:
      scrape_interval: 15s
      evaluation_interval: 15s

    alerting:
      alertmanagers:
        - static_configs:
            - targets:
              - alertmanager:9093

    scrape_configs:
      - job_name: 'prometheus'
        static_configs:
          - targets: ['localhost:9090']

      - job_name: 'healthcare-ai'
        static_configs:
          - targets: ['healthcare-ai:8000']
        metrics_path: '/metrics'
        scrape_interval: 10s

      - job_name: 'ab-testing'
        static_configs:
          - targets: ['ab-testing:8000']
        metrics_path: '/metrics'
        scrape_interval: 5s

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: alertmanager-config
  namespace: healthcare-ai-production
data:
  alertmanager.yml: |
    global:
      smtp_smarthost: 'localhost:587'
      smtp_from: 'alerts@healthcare-ai-production.com'

    route:
      group_by: ['alertname']
      group_wait: 10s
      group_interval: 10s
      repeat_interval: 1h
      receiver: 'production-alerts'

    receivers:
    - name: 'production-alerts'
      webhook_configs:
      - url: 'http://ab-testing:8000/webhook/alerts'
        send_resolved: true

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: prometheus
  namespace: healthcare-ai-production
  labels:
    app: prometheus
    environment: production
spec:
  replicas: 3
  selector:
    matchLabels:
      app: prometheus
  template:
    metadata:
      labels:
        app: prometheus
    spec:
      securityContext:
        runAsNonRoot: true
        runAsUser: 65534
        fsGroup: 65534
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - prometheus
            topologyKey: "kubernetes.io/hostname"
      containers:
      - name: prometheus
        image: prom/prometheus:v2.45.0
        ports:
        - containerPort: 9090
        args:
        - '--config.file=/etc/prometheus/prometheus.yml'
        - '--storage.tsdb.path=/prometheus'
        - '--web.console.libraries=/etc/prometheus/console_libraries'
        - '--web.console.templates=/etc/prometheus/consoles'
        - '--storage.tsdb.retention.time=90d'
        - '--web.enable-lifecycle'
        volumeMounts:
        - name: prometheus-config
          mountPath: /etc/prometheus
        - name: prometheus-storage
          mountPath: /prometheus
        resources:
          requests:
            memory: "4Gi"
            cpu: "2000m"
          limits:
            memory: "8Gi"
            cpu: "4000m"
      volumes:
      - name: prometheus-config
        configMap:
          name: prometheus-config
      - name: prometheus-storage
        persistentVolumeClaim:
          claimName: prometheus-pvc

---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: prometheus-pvc
  namespace: healthcare-ai-production
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 200Gi

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: alertmanager
  namespace: healthcare-ai-production
  labels:
    app: alertmanager
    environment: production
spec:
  replicas: 3
  selector:
    matchLabels:
      app: alertmanager
  template:
    metadata:
      labels:
        app: alertmanager
    spec:
      securityContext:
        runAsNonRoot: true
        runAsUser: 65534
        fsGroup: 65534
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - alertmanager
            topologyKey: "kubernetes.io/hostname"
      containers:
      - name: alertmanager
        image: prom/alertmanager:v0.25.0
        ports:
        - containerPort: 9093
        args:
        - '--config.file=/etc/alertmanager/alertmanager.yml'
        - '--storage.path=/alertmanager'
        volumeMounts:
        - name: alertmanager-config
          mountPath: /etc/alertmanager
        - name: alertmanager-storage
          mountPath: /alertmanager
        resources:
          requests:
            memory: "1Gi"
            cpu: "500m"
          limits:
            memory: "2Gi"
            cpu: "1000m"
      volumes:
      - name: alertmanager-config
        configMap:
          name: alertmanager-config
      - name: alertmanager-storage
        persistentVolumeClaim:
          claimName: alertmanager-pvc

---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: alertmanager-pvc
  namespace: healthcare-ai-production
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 50Gi

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: grafana
  namespace: healthcare-ai-production
  labels:
    app: grafana
    environment: production
spec:
  replicas: 3
  selector:
    matchLabels:
      app: grafana
  template:
    metadata:
      labels:
        app: grafana
    spec:
      securityContext:
        runAsNonRoot: true
        runAsUser: 472
        fsGroup: 472
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - grafana
            topologyKey: "kubernetes.io/hostname"
      containers:
      - name: grafana
        image: grafana/grafana:10.0.0
        ports:
        - containerPort: 3000
        env:
        - name: GF_SECURITY_ADMIN_PASSWORD
          value: "admin123"
        - name: GF_INSTALL_PLUGINS
          value: "grafana-piechart-panel"
        volumeMounts:
        - name: grafana-storage
          mountPath: /var/lib/grafana
        resources:
          requests:
            memory: "2Gi"
            cpu: "1000m"
          limits:
            memory: "4Gi"
            cpu: "2000m"
      volumes:
      - name: grafana-storage
        persistentVolumeClaim:
          claimName: grafana-pvc

---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: grafana-pvc
  namespace: healthcare-ai-production
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 100Gi

---
# Services for monitoring stack
apiVersion: v1
kind: Service
metadata:
  name: prometheus
  namespace: healthcare-ai-production
  labels:
    app: prometheus
spec:
  ports:
  - port: 9090
    targetPort: 9090
  selector:
    app: prometheus

---
apiVersion: v1
kind: Service
metadata:
  name: prometheus-external
  namespace: healthcare-ai-production
  labels:
    app: prometheus
spec:
  type: NodePort
  ports:
  - port: 9090
    targetPort: 9090
    nodePort: 31109
  selector:
    app: prometheus

---
apiVersion: v1
kind: Service
metadata:
  name: alertmanager
  namespace: healthcare-ai-production
  labels:
    app: alertmanager
spec:
  ports:
  - port: 9093
    targetPort: 9093
  selector:
    app: alertmanager

---
apiVersion: v1
kind: Service
metadata:
  name: alertmanager-external
  namespace: healthcare-ai-production
  labels:
    app: alertmanager
spec:
  type: NodePort
  ports:
  - port: 9093
    targetPort: 9093
    nodePort: 31130
  selector:
    app: alertmanager

---
apiVersion: v1
kind: Service
metadata:
  name: grafana
  namespace: healthcare-ai-production
  labels:
    app: grafana
spec:
  ports:
  - port: 3000
    targetPort: 3000
  selector:
    app: grafana

---
apiVersion: v1
kind: Service
metadata:
  name: grafana-external
  namespace: healthcare-ai-production
  labels:
    app: grafana
spec:
  type: NodePort
  ports:
  - port: 3000
    targetPort: 3000
    nodePort: 30500
  selector:
    app: grafana